{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will with the help of the Medium Cookies we will sign-in the Medium.com site we will extarct the data from it and with the help of the Bs4 we will import BeautifulSoup with which we will make a Database.csv file that hold all the Data in it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the important needed stuff for the Extraction of Data from the Medium site "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import json\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options()\n",
    "# options.add_argument(\"--headless\") \n",
    "# options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = uc.Chrome()\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"https://www.medium.com\")\n",
    "\n",
    "with open('cookies_medium.json','r') as file:\n",
    "  all_cookies = json.load(file)\n",
    "\n",
    "for cookies in all_cookies:\n",
    "  if 'medium.com' in cookies.get('domain',''):\n",
    "    driver.add_cookie(cookies)\n",
    "\n",
    "driver.get(\"https://www.medium.com\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_value=driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[1]/div/div/input\")\n",
    "time.sleep(4)\n",
    "data_value.send_keys('Data Science')\n",
    "data_value.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current height be :933\n"
     ]
    }
   ],
   "source": [
    "height=driver.execute_script(' return document.body.scrollHeight')\n",
    "print(f'current height be :{height}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'/html/body/div[1]/div/div[3]/div[2]/div/main/div/div/div[2]/div/div[10]/div/div/button'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current Scroll\n",
      "New Scroll\n",
      "current Scroll\n",
      "New Scroll\n",
      "current Scroll\n",
      "New Scroll\n",
      "current Scroll\n",
      "New Scroll\n",
      "current Scroll\n",
      "New Scroll\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "\n",
    "  driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
    "  time.sleep(3)\n",
    "  print(f'current Scroll')\n",
    "\n",
    "  show_button=WebDriverWait(driver,10).until(\n",
    "    EC.element_to_be_clickable(\n",
    "      driver.find_element(By.XPATH,\"//button[contains(text(), 'Show more')]\")\n",
    "      ))\n",
    "  show_button.click()\n",
    "\n",
    "  time.sleep(3)\n",
    "  driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
    "  print(f'New Scroll')\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.CLASS_NAME, \"n p\"))\n",
    ")\n",
    "\n",
    "# Pass the updated page source to BeautifulSoup\n",
    "new_values = BeautifulSoup(driver.page_source, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Towards Data Science\n",
      "++++\n",
      "Jason Tamara Widjaja\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "Claudia Ng\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "Anna Via\n",
      "++++\n",
      "Stackademic\n",
      "++++\n",
      "Abdur Rahman\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "Egor Howell\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "Benjamin Bodner\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "Sabrine Bendimerad\n",
      "++++\n",
      "Emmanuel Ikogho\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "Jose Parre√±o\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "Jose Parre√±o\n",
      "++++\n",
      "Harika Govada\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "Dario Radeƒçiƒá\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "Benjamin Lee\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "üí°Mike Shakhomirov\n",
      "++++\n",
      "Towards AI\n",
      "++++\n",
      "Joseph Robinson, Ph.D.\n",
      "++++\n",
      "Level Up Coding\n",
      "++++\n",
      "Joseph Robinson, Ph.D.\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "Dasha Herrmannova, Ph.D.\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "Col Jung\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "Yu Dong\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "Egor Howell\n",
      "++++\n",
      "Bhavik Jikadara\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "Khouloud El Alami\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "bitgrit Data Science Publication\n",
      "++++\n",
      "Benedict Neo\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "Matt Chapman\n",
      "++++\n",
      "bitgrit Data Science Publication\n",
      "++++\n",
      "Benedict Neo\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "Sara N√≥brega\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "Egor Howell\n",
      "++++\n",
      "Towards Data Science\n",
      "++++\n",
      "Egor Howell\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "Aqsazafar\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "NYU Center for Data Science\n",
      "++++\n",
      "Mirko Peters\n",
      "++++\n",
      "NYU Center for Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "Zoumana Keita\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "ODSC - Open Data Science\n",
      "++++\n",
      "Towards Data Science\n",
      "----\n",
      "Jason Tamara Widjaja\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "Claudia Ng\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "Anna Via\n",
      "----\n",
      "Stackademic\n",
      "----\n",
      "Abdur Rahman\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "Egor Howell\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "Benjamin Bodner\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "Sabrine Bendimerad\n",
      "----\n",
      "Emmanuel Ikogho\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "Jose Parre√±o\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "Jose Parre√±o\n",
      "----\n",
      "Harika Govada\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "Dario Radeƒçiƒá\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "Benjamin Lee\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "üí°Mike Shakhomirov\n",
      "----\n",
      "Towards AI\n",
      "----\n",
      "Joseph Robinson, Ph.D.\n",
      "----\n",
      "Level Up Coding\n",
      "----\n",
      "Joseph Robinson, Ph.D.\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "Dasha Herrmannova, Ph.D.\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "Col Jung\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "Yu Dong\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "Egor Howell\n",
      "----\n",
      "Bhavik Jikadara\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "Khouloud El Alami\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "bitgrit Data Science Publication\n",
      "----\n",
      "Benedict Neo\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "Matt Chapman\n",
      "----\n",
      "bitgrit Data Science Publication\n",
      "----\n",
      "Benedict Neo\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "Sara N√≥brega\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "Egor Howell\n",
      "----\n",
      "Towards Data Science\n",
      "----\n",
      "Egor Howell\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "Aqsazafar\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "NYU Center for Data Science\n",
      "----\n",
      "Mirko Peters\n",
      "----\n",
      "NYU Center for Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "Zoumana Keita\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n",
      "ODSC - Open Data Science\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "new_data = new_values.find_all('p',{'class':'ar b aq am gg gh gi gj gk gl gm gn bx'}) \n",
    "for i in new_data:\n",
    "  print(i.text)\n",
    "  print('++++')\n",
    "\n",
    "author_name = new_values.find_all('p',{'class':'ar b aq am gg gh gi gj gk gl gm gn bx'})\n",
    "for i in author_name:\n",
    "  print(i.text)\n",
    "  print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dec 30, 2024\n",
      "Dec 30, 2024\n",
      "Nov 28, 2024\n",
      "Nov 28, 2024\n",
      "Nov 29, 2024\n",
      "Nov 29, 2024\n",
      "Oct 23, 2024\n",
      "Oct 23, 2024\n",
      "Oct 25, 2024\n",
      "Oct 25, 2024\n",
      "Oct 22, 2024\n",
      "Oct 22, 2024\n",
      "Oct 3, 2024\n",
      "Oct 3, 2024\n",
      "Sep 3, 2024\n",
      "Sep 3, 2024\n",
      "Sep 5, 2024\n",
      "Sep 5, 2024\n",
      "Sep 12, 2024\n",
      "Sep 12, 2024\n",
      "Sep 2, 2024\n",
      "Sep 2, 2024\n",
      "Aug 2, 2024\n",
      "Aug 2, 2024\n",
      "Aug 28, 2024\n",
      "Aug 28, 2024\n",
      "Aug 24, 2024\n",
      "Aug 24, 2024\n",
      "Aug 14, 2024\n",
      "Aug 14, 2024\n",
      "Aug 23, 2024\n",
      "Aug 23, 2024\n",
      "Jul 13, 2024\n",
      "Jul 13, 2024\n",
      "Jul 24, 2024\n",
      "Jul 24, 2024\n",
      "Jul 10, 2024\n",
      "Jul 10, 2024\n",
      "Jul 13, 2024\n",
      "Jul 13, 2024\n",
      "Jul 28, 2024\n",
      "Jul 28, 2024\n",
      "Jul 7, 2024\n",
      "Jul 7, 2024\n",
      "Jul 4, 2024\n",
      "Jul 4, 2024\n",
      "Jul 8, 2024\n",
      "Jul 8, 2024\n",
      "Jun 14, 2024\n",
      "Jun 14, 2024\n",
      "Jun 4, 2024\n",
      "Jun 4, 2024\n",
      "Jun 3, 2024\n",
      "Jun 3, 2024\n",
      "Jun 5, 2024\n",
      "Jun 5, 2024\n",
      "Jun 23, 2024\n",
      "Jun 23, 2024\n",
      "Jun 8, 2024\n",
      "Jun 8, 2024\n",
      "Jun 11, 2024\n",
      "Jun 11, 2024\n",
      "Jun 26, 2024\n",
      "Jun 26, 2024\n",
      "Jun 5, 2024\n",
      "Jun 5, 2024\n",
      "Jun 19, 2024\n",
      "Jun 19, 2024\n",
      "Jun 3, 2024\n",
      "Jun 3, 2024\n",
      "Jun 7, 2024\n",
      "Jun 7, 2024\n",
      "Jun 6, 2024\n",
      "Jun 6, 2024\n",
      "Jun 4, 2024\n",
      "Jun 4, 2024\n",
      "Jun 7, 2024\n",
      "Jun 7, 2024\n",
      "Jun 3, 2024\n",
      "Jun 3, 2024\n",
      "Jun 21, 2024\n",
      "Jun 21, 2024\n",
      "Jun 18, 2024\n",
      "Jun 18, 2024\n",
      "Jun 22, 2024\n",
      "Jun 22, 2024\n",
      "Jun 12, 2024\n",
      "Jun 12, 2024\n",
      "Jun 21, 2024\n",
      "Jun 21, 2024\n",
      "Jun 25, 2024\n",
      "Jun 25, 2024\n",
      "Jun 6, 2024\n",
      "Jun 6, 2024\n",
      "Jun 4, 2024\n",
      "Jun 4, 2024\n",
      "Jun 12, 2024\n",
      "Jun 12, 2024\n",
      "Jun 20, 2024\n",
      "Jun 20, 2024\n",
      "Jun 28, 2024\n",
      "Jun 28, 2024\n",
      "Jun 6, 2024\n",
      "Jun 6, 2024\n",
      "Jun 7, 2024\n",
      "Jun 7, 2024\n",
      "Jun 7, 2024\n",
      "Jun 7, 2024\n",
      "Jun 28, 2024\n",
      "Jun 28, 2024\n",
      "Jun 21, 2024\n",
      "Jun 21, 2024\n",
      "Jun 14, 2024\n",
      "Jun 14, 2024\n",
      "Jun 10, 2024\n",
      "Jun 10, 2024\n",
      "Jun 21, 2024\n",
      "Jun 21, 2024\n",
      "Jun 19, 2024\n",
      "Jun 19, 2024\n"
     ]
    }
   ],
   "source": [
    "# Find all <div> elements with the specified class\n",
    "new_date = new_values.find_all('div', class_='n o gq')\n",
    "span_dates=[]\n",
    "\n",
    "# Extract text from <span> elements inside `new_date`\n",
    "for div in new_date:\n",
    "    date_spans = div.find_all('span')  \n",
    "    for span in date_spans:\n",
    "        if '2024' in span.text: \n",
    "            span_dates.append(span.text.strip())  \n",
    "\n",
    "for i in span_dates:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_k = new_values.find_all('div', class_='cf pr dx n o')\n",
    "span_dates_k=[]\n",
    "\n",
    "# Extract text from <span> elements inside `new_k`\n",
    "for div in new_k:\n",
    "    date_spans = div.find_all('span')  \n",
    "    lenght = len(date_spans)\n",
    "    \n",
    "    # print(lenght)\n",
    "    if lenght ==1 or lenght<=2:\n",
    "        if date_spans[1:] is not  None:\n",
    "            for span in date_spans[1:]:\n",
    "                    span_dates_k.append(span.text.strip())\n",
    "                \n",
    "                \n",
    "for i in span_dates_k:\n",
    "     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_k = new_values.find_all('div', class_='cf pr dx n o')\n",
    "span_dates_k =  []\n",
    "new_values_convert = []\n",
    "new_dotless = []\n",
    "\n",
    "for div in new_k:\n",
    "    date_spans = div.find_all('span')  \n",
    "    length = len(date_spans)\n",
    "\n",
    "    if length >=1:  \n",
    "        for span in date_spans[:1]:\n",
    "            span_text = span.text.strip()\n",
    "            # print(span_text)\n",
    "            if span_text :\n",
    "                span_dates_k.append(span_text)\n",
    "\n",
    "for dots in span_dates_k:\n",
    "    if 'K' in dots:\n",
    "        dosy_data_without_k=dots.replace('K','')\n",
    "        if '.' in dosy_data_without_k:\n",
    "                dosy_data_without_k=dosy_data_without_k.replace('.','')\n",
    "                new_dotless.append(dosy_data_without_k+'00')\n",
    "        else:\n",
    "                new_dotless.append(dosy_data_without_k+'000')\n",
    "    else :\n",
    "        new_dotless.append(dots)\n",
    "\n",
    "                \n",
    "for i in new_dotless:\n",
    "    if i:\n",
    "        print(i)\n",
    "    else:\n",
    "        print('Empty')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_k = new_values.find_all('div', class_='cf pr dx n o')\n",
    "span_dates_k = set()  # Use set to avoid duplicates\n",
    "new_dotless = []\n",
    "\n",
    "# Extract span text and store unique values in span_dates_k\n",
    "for div in new_k:\n",
    "    date_spans = div.find_all('span')\n",
    "    if date_spans:\n",
    "        span_text = date_spans[1].text.strip()  # Get the first span text\n",
    "        if span_text:\n",
    "            span_dates_k.add(span_text)  # Use add() to store unique values\n",
    "\n",
    "# Process values from span_dates_k and perform replacements\n",
    "for dots in span_dates_k:\n",
    "    if 'K' in dots:\n",
    "        dosy_data_without_k = dots.replace('K', '')  # Remove 'K'\n",
    "\n",
    "        if '.' in dosy_data_without_k:\n",
    "            dots_less_data = dosy_data_without_k.replace('.', '')  # Remove dot\n",
    "            new_dotless.append(dots_less_data + '00')  # Append '00'\n",
    "        else:\n",
    "            new_dotless.append(dosy_data_without_k + '000')  # Append '000'\n",
    "    else:\n",
    "        new_dotless.append(dots)\n",
    "\n",
    "# Print the results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
