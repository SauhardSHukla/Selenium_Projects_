{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will with the help of the Medium Cookies we will sign-in the Medium.com site we will extarct the data from it and with the help of the Bs4 we will import BeautifulSoup with which we will make a Database.csv file that hold all the Data in it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the important needed stuff for the Extraction of Data from the Medium site "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\") \n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Navigate to Medium\n",
    "driver.get(\"https://www.medium.com\")\n",
    "\n",
    "# Load cookies from JSON\n",
    "with open('cookies_medium_2.json', 'r') as file:\n",
    "    all_cookies = json.load(file)\n",
    "\n",
    "# Clear existing cookies\n",
    "driver.delete_all_cookies()\n",
    "\n",
    "# Add cookies\n",
    "for cookie in all_cookies:\n",
    "    if '.medium.com' in cookie.get('domain', ''):\n",
    "        driver.add_cookie(cookie)\n",
    "\n",
    "# Refresh page to apply cookies\n",
    "driver.get(\"https://medium.com\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Check if login was successful\n",
    "# print(driver.get_cookies())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_value=driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[1]/div/div/input\")\n",
    "time.sleep(4)\n",
    "data_value.send_keys('Data Science')\n",
    "data_value.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current height be :933\n"
     ]
    }
   ],
   "source": [
    "height=driver.execute_script(' return document.body.scrollHeight')\n",
    "print(f'current height be :{height}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'/html/body/div[1]/div/div[3]/div[2]/div/main/div/div/div[2]/div/div[10]/div/div/button'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current Scroll\n",
      "New Scroll\n",
      "current Scroll\n",
      "New Scroll\n",
      "current Scroll\n",
      "New Scroll\n",
      "current Scroll\n",
      "New Scroll\n",
      "current Scroll\n",
      "New Scroll\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "\n",
    "  driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
    "  time.sleep(3)\n",
    "  print(f'current Scroll')\n",
    "\n",
    "  show_button=WebDriverWait(driver,10).until(\n",
    "    EC.element_to_be_clickable(\n",
    "      driver.find_element(By.XPATH,\"//button[contains(text(), 'Show more')]\")\n",
    "      ))\n",
    "  show_button.click()\n",
    "\n",
    "  time.sleep(3)\n",
    "  driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
    "  print(f'New Scroll')\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.CLASS_NAME, \"n p\"))\n",
    ")\n",
    "\n",
    "# Pass the updated page source to BeautifulSoup\n",
    "new_values = BeautifulSoup(driver.page_source, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Towards Data Science', 'Towards Data Science', 'Towards Data Science', 'Stackademic', 'Towards Data Science', 'Towards Data Science', 'Towards Data Science', 'Emmanuel Ikogho', 'Towards Data Science', 'Towards Data Science', 'Harika Govada', 'Towards Data Science', 'Towards Data Science', 'Towards Data Science', 'Towards AI', 'Level Up Coding', 'Towards Data Science', 'Towards Data Science', 'Towards Data Science', 'Towards Data Science', 'Bhavik Jikadara', 'Towards Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'bitgrit Data Science Publication', 'Towards Data Science', 'bitgrit Data Science Publication', 'Towards Data Science', 'Towards Data Science', 'Towards Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'Aqsazafar', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'NYU Center for Data Science', 'Mirko Peters', 'NYU Center for Data Science', 'ODSC - Open Data Science', 'Zoumana Keita', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science', 'ODSC - Open Data Science']\n",
      "['Jason Tamara Widjaja', 'Claudia Ng', 'Anna Via', 'Abdur Rahman', 'Egor Howell', 'Benjamin Bodner', 'Sabrine Bendimerad', 'None', 'Jose Parre√±o', 'Jose Parre√±o', 'None', 'Dario Radeƒçiƒá', 'Benjamin Lee', 'üí°Mike Shakhomirov', 'Joseph Robinson, Ph.D.', 'Joseph Robinson, Ph.D.', 'Dasha Herrmannova, Ph.D.', 'Col Jung', 'Yu Dong', 'Egor Howell', 'None', 'Khouloud El Alami', 'None', 'None', 'Benedict Neo', 'Matt Chapman', 'Benedict Neo', 'Sara N√≥brega', 'Egor Howell', 'Egor Howell', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None']\n"
     ]
    }
   ],
   "source": [
    "divs = new_values.find_all('div', class_='m mn mo mp mq')\n",
    "\n",
    "if divs:  \n",
    "    def all_names(divs):\n",
    "        \n",
    "        # Extract title and author name both from <p> tags with the same class\n",
    "        title_data = divs.find('p', {'class': 'ar b aq am gg gh gi gj gk gl gm gn bx'})\n",
    "        author_name_data = divs.find_all('p', {'class': 'ar b aq am gg gh gi gj gk gl gm gn bx'}) \n",
    "\n",
    "        # Extract the title text from the first <p> tag\n",
    "        title_text = title_data.text.strip() if title_data else 'None'\n",
    "        author_name_text = author_name_data[1].text.strip() if len(author_name_data) > 1 else 'None'\n",
    "\n",
    "        return title_text, author_name_text,\n",
    "\n",
    "    # Initialize lists to store titles and author names\n",
    "    titles = []\n",
    "    author_names = []\n",
    "\n",
    "\n",
    "\n",
    "    # Process each div and collect titles and author names\n",
    "    for div in divs:\n",
    "        title, author= all_names(div)\n",
    "\n",
    "        titles.append(title)\n",
    "        author_names.append(author)\n",
    "        \n",
    "  \n",
    "print(titles)\n",
    "print(author_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Find all <div> elements with the specified class\n",
    "new_date = new_values.find_all('div', class_='n o gq')\n",
    "span_dates=[]\n",
    "\n",
    "# Extract text from <span> elements inside `new_date`\n",
    "for div in new_date[0::2]:\n",
    "    date_spans = div.find_all('span')  \n",
    "    for span in date_spans:\n",
    "        if span:\n",
    "            if '2024' in span.text: \n",
    "                span_dates.append(span.text.strip()) \n",
    "        else :\n",
    "            span_dates.append('None') \n",
    "\n",
    "\n",
    "# for i in span_dates:\n",
    "    # print(i)\n",
    "print(len(span_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "div_ = new_values.find_all('div', class_=\"cf or dx n o\")\n",
    "\n",
    "if div_:\n",
    "    def cmt(div):\n",
    "        likes = div.find('span')\n",
    "        cmt = div.find_all('span')\n",
    "\n",
    "        total_likes = likes.text.strip() if likes else '0'\n",
    "        total_cmt = cmt[1].text.strip() if len(cmt)>1 else '0'\n",
    "        if total_likes:\n",
    "            if 'K' in total_likes:\n",
    "                dosy_data_without_k=total_likes.replace('K','')\n",
    "                if '.' in dosy_data_without_k:\n",
    "                    dosy_data_without_k=dosy_data_without_k.replace('.','')\n",
    "                    dosy_data_without_k+='00'\n",
    "                else:\n",
    "                    dosy_data_without_k+='000'\n",
    "            else:\n",
    "                dosy_data_without_k=total_likes\n",
    "            \n",
    "\n",
    "        return total_cmt,dosy_data_without_k\n",
    "    \n",
    "\n",
    "    cmt_list =[]\n",
    "    likes_list =[]\n",
    "\n",
    "    for div in div_:\n",
    "        comment,likes = cmt(div)\n",
    "        cmt_list.append(comment)\n",
    "        likes_list.append(likes)\n",
    "        \n",
    "\n",
    "\n",
    "# print(len(likes_list))\n",
    "# print(len(cmt_list))\n",
    "\n",
    "new_list_likes=[]\n",
    "for i in likes_list[0::2]:\n",
    "    # print(i)\n",
    "    new_list_likes.append(i)\n",
    "new_list_cmt=[]\n",
    "for i in cmt_list[0::2]:\n",
    "    # print(i)\n",
    "    new_list_cmt.append(i)\n",
    "\n",
    "\n",
    "print(len(new_list_cmt))\n",
    "print(len(new_list_likes))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# new_k = new_values.find_all('div', class_='cf or dx n o')\n",
    "# span_dates_k =  []\n",
    "# new_values_convert = []\n",
    "# new_dotless = []\n",
    "\n",
    "# for div in new_k[0::2]:\n",
    "#     date_spans = div.find_all('span')  \n",
    "#     length = len(date_spans)\n",
    "\n",
    "#     if length >=1:  \n",
    "#         for span in date_spans[:1]:\n",
    "#             span_text = span.text.strip()\n",
    "#             # print(span_text)\n",
    "#             if span_text :\n",
    "#                 span_dates_k.append(span_text)\n",
    "\n",
    "# for dots in span_dates_k:\n",
    "#     if dots:\n",
    "#         if 'K' in dots:\n",
    "#             dosy_data_without_k=dots.replace('K','')\n",
    "#             if '.' in dosy_data_without_k:\n",
    "#                 dosy_data_without_k=dosy_data_without_k.replace('.','')\n",
    "#                 new_dotless.append(dosy_data_without_k+'00')\n",
    "#             else:\n",
    "#                 new_dotless.append(dosy_data_without_k+'000')\n",
    "#         else:\n",
    "#             new_dotless.append(dots)\n",
    "#     else:\n",
    "#         new_dotless.append(0)\n",
    "\n",
    "# print(f'newlen:{len(span_dates_cmt)}')       \n",
    "# for i in new_dotless:\n",
    "#     if i:\n",
    "#         print(i)\n",
    "#     else:\n",
    "#         print('Empty')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
